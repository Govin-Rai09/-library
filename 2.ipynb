{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOl/c9JXGQGUwpsAoEmCT4d",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Govin-Rai09/-library/blob/main/2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Vf8tmE9wEIE",
        "outputId": "57d22086-8e24-4cf1-de0b-58e35ff9a8c3"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOAnGdqAy3vk"
      },
      "source": [
        "df=pd.read_csv('/content/gdrive/MyDrive/datasets/creditcard.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qALr4Isy8R6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rn2fXyu6y9uh"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrdipG9yzA1M"
      },
      "source": [
        "df['Class'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X1HXa9AfzGeB"
      },
      "source": [
        "X=df.drop('Class',axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1g_kOZqMzovi"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8krc0d4zqVF"
      },
      "source": [
        "y=df['Class']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK5JiFELzxNx"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YxTXefFhzygC"
      },
      "source": [
        "y.shape,X.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCurmYAHz70y"
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QAAnX3Ar0y-J"
      },
      "source": [
        "df.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LTt-gP_b1WEL"
      },
      "source": [
        "df.dropna(inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krQ3lKtK1bBg"
      },
      "source": [
        "df.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoIXvA241iLL"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ9B7Z931luy"
      },
      "source": [
        "df.describe().transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WtsXf5Ii2EGY"
      },
      "source": [
        "**Exploratory Data Analysis**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ihYz4XDzaSGe"
      },
      "source": [
        "df.iloc[1,2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OASOAsp8aRvz"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtcNYFY60D8z"
      },
      "source": [
        "from collections import Counter"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-QoMyYt4fGH"
      },
      "source": [
        "print('counts {}'.format(Counter(X)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF5vjYzN4e4e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqVp40Ni0cNa"
      },
      "source": [
        "count_class=pd.value_counts(df['Class'],sort=True)\n",
        "count_class.plot(kind='bar',rot=0)\n",
        "plt.title('Transaction Class',fontsize=18)\n",
        "plt.xticks(range(2),labels=['Normal','Fraud'])\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95IQ7vXZ4VNo"
      },
      "source": [
        "df['Class'].value_counts().plot(kind='bar',rot=0)\n",
        "plt.xticks(range(2),labels=['Normal','Fraud'])\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7neYRarv4Vkp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1-yvcLS2fp9"
      },
      "source": [
        "Fraud=df[df['Class']==1]\n",
        "Normal=df[df['Class']==0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMB-WOf2_z3O"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VsLrUkEgAZ1e"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDFawGQBAZyU"
      },
      "source": [
        "X_train.shape,y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3mx9yOSAZvL"
      },
      "source": [
        "model=KNeighborsClassifier()\n",
        "model=model.fit(X_train,y_train)\n",
        "y_pred=model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r4XHW-gsAZlT"
      },
      "source": [
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc15tXBNFTcC"
      },
      "source": [
        "accuracy_score(y_test,y_pred)\n",
        "pd.crosstab(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bvW2ElTy3168"
      },
      "source": [
        "Fraud.shape,Normal.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ps2wTyaO37B_"
      },
      "source": [
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82HLMzLr4GF1"
      },
      "source": [
        "smote=SMOTE()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "igOrKmdrCs-X"
      },
      "source": [
        "X_train.shape,y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFFWa-8S-Aou"
      },
      "source": [
        "X_train_smo,y_train_smo=smote.fit_sample(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3q8V722Cflm"
      },
      "source": [
        "X_train_smo.shape,y_train_smo.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhSWElRODUPl"
      },
      "source": [
        "print('Before SMOTE :',Counter(y_train))\n",
        "print('After SMOTE :',Counter(y_train_smo))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zd14BBUiDn42"
      },
      "source": [
        "model=KNeighborsClassifier()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lzQ7h-jELGA"
      },
      "source": [
        "model.fit(X_train_smo,y_train_smo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9QAMdmMEP1A"
      },
      "source": [
        "y_pred=model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14iD1RpeEU2_"
      },
      "source": [
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzNkVXD0F8t8"
      },
      "source": [
        "pd.crosstab(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGkg3NN3GAvE"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix,f1_score,precision_score,recall_score,roc_auc_score,roc_curve\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLW2zfGyHfpt"
      },
      "source": [
        "confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgKux-4UHj9Q"
      },
      "source": [
        "f1_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUSBBIVkHpXp"
      },
      "source": [
        "precision_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlogodimHtIM"
      },
      "source": [
        "recall_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yyO43-OmHwy2"
      },
      "source": [
        "roc_curve(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6hzt5VB2H6ut"
      },
      "source": [
        "roc_auc_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fn6gqGNVH_iH"
      },
      "source": [
        "from imblearn.under_sampling import NearMiss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9eFKCO0JB7B"
      },
      "source": [
        "import sklearn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExStFVCfSuNy"
      },
      "source": [
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B4jGdOoTroN"
      },
      "source": [
        "mess=pd.read_csv('SMSSpamCollection',sep='\\t',names=['Label','message'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "LDhDV_4GT9aI",
        "outputId": "39076255-8399-4d6f-fbef-7a4eb63ffa03"
      },
      "source": [
        "mess.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Label                                            message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bww0tCQiUIGR",
        "outputId": "af2a41fd-91b4-46a8-990c-f92e4a0a98da"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vekGkQNIUQq6"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "from nltk import sent_tokenize,word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGjW_HmaUeIz"
      },
      "source": [
        "from nltk.stem import PorterStemmer,WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5n8KLT5BUkUj",
        "outputId": "af2de76b-7569-47d4-9307-7988a49b2744"
      },
      "source": [
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZGovLsKUnmF",
        "outputId": "9c03d17b-d1f2-45d6-d54d-ffe2aa545bb0"
      },
      "source": [
        "mess.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5572 entries, 0 to 5571\n",
            "Data columns (total 2 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   Label    5572 non-null   object\n",
            " 1   message  5572 non-null   object\n",
            "dtypes: object(2)\n",
            "memory usage: 87.2+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "1Ngf4qP9U12F",
        "outputId": "b976dc41-b7cc-4851-f459-920e65530a04"
      },
      "source": [
        "mess.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Label</th>\n",
              "      <th>message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>5572</td>\n",
              "      <td>5572</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>2</td>\n",
              "      <td>5169</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>ham</td>\n",
              "      <td>Sorry, I'll call later</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>4825</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Label                 message\n",
              "count   5572                    5572\n",
              "unique     2                    5169\n",
              "top      ham  Sorry, I'll call later\n",
              "freq    4825                      30"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V4gjtQFFWZQM",
        "outputId": "dc2ef150-9821-4467-ddb6-dd60a99bdbce"
      },
      "source": [
        "mess.isnull().values.any()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5gMLu97WZaa"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be9yAZMVWZcV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWTgvgFzU4ro"
      },
      "source": [
        "import re\n",
        "lemmetizer=WordNetLemmatizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "udsN_XK0U_jy"
      },
      "source": [
        "corpus=[]\n",
        "for i in range(0,len(mess)):\n",
        "  words=re.sub('[^a-zA-Z]',' ',mess['message'][i])\n",
        "  words=words.lower()\n",
        "  words=words.split()\n",
        "  words=[lemmetizer.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
        "  words=' '.join(words)\n",
        "  corpus.append(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qGif7KGaKGQ",
        "outputId": "272e9164-6070-4079-b6ca-c68b4eacf05b"
      },
      "source": [
        "corpus[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['go jurong point crazy available bugis n great world la e buffet cine got amore wat',\n",
              " 'ok lar joking wif u oni',\n",
              " 'free entry wkly comp win fa cup final tkts st may text fa receive entry question std txt rate c apply',\n",
              " 'u dun say early hor u c already say',\n",
              " 'nah think go usf life around though',\n",
              " 'freemsg hey darling week word back like fun still tb ok xxx std chgs send rcv',\n",
              " 'even brother like speak treat like aid patent',\n",
              " 'per request melle melle oru minnaminunginte nurungu vettam set callertune caller press copy friend callertune',\n",
              " 'winner valued network customer selected receivea prize reward claim call claim code kl valid hour',\n",
              " 'mobile month u r entitled update latest colour mobile camera free call mobile update co free']"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmlEuDN5V0Xv"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Bb4F3oyWNCK"
      },
      "source": [
        "tfv=TfidfVectorizer(max_features=5000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmG5EKQsWSa8"
      },
      "source": [
        "X=tfv.fit_transform(corpus).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6NN0smZZW75T"
      },
      "source": [
        "y=pd.get_dummies(mess['Label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_7ot8PzXAZs",
        "outputId": "d8099f2d-70b5-44da-b5ed-610a0b1e9a35"
      },
      "source": [
        "X.shape,y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((5572, 5000), (5572, 2))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEX93gQRXdI5"
      },
      "source": [
        "X=pd.DataFrame(X,columns=tfv.get_feature_names())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "o4dyLz7rXr-z",
        "outputId": "20e7391a-0ae2-4649-c3b0-eb4eae523dfd"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>aa</th>\n",
              "      <th>aah</th>\n",
              "      <th>aathi</th>\n",
              "      <th>abi</th>\n",
              "      <th>ability</th>\n",
              "      <th>abiola</th>\n",
              "      <th>abj</th>\n",
              "      <th>able</th>\n",
              "      <th>absolutly</th>\n",
              "      <th>abt</th>\n",
              "      <th>abta</th>\n",
              "      <th>aburo</th>\n",
              "      <th>ac</th>\n",
              "      <th>academic</th>\n",
              "      <th>acc</th>\n",
              "      <th>accept</th>\n",
              "      <th>access</th>\n",
              "      <th>accident</th>\n",
              "      <th>accidentally</th>\n",
              "      <th>accordingly</th>\n",
              "      <th>account</th>\n",
              "      <th>ache</th>\n",
              "      <th>acl</th>\n",
              "      <th>aco</th>\n",
              "      <th>across</th>\n",
              "      <th>acted</th>\n",
              "      <th>acting</th>\n",
              "      <th>action</th>\n",
              "      <th>activate</th>\n",
              "      <th>active</th>\n",
              "      <th>activity</th>\n",
              "      <th>actor</th>\n",
              "      <th>actual</th>\n",
              "      <th>actually</th>\n",
              "      <th>ad</th>\n",
              "      <th>adam</th>\n",
              "      <th>add</th>\n",
              "      <th>addamsfa</th>\n",
              "      <th>added</th>\n",
              "      <th>addicted</th>\n",
              "      <th>...</th>\n",
              "      <th>yogasana</th>\n",
              "      <th>yor</th>\n",
              "      <th>yorge</th>\n",
              "      <th>youdoing</th>\n",
              "      <th>youi</th>\n",
              "      <th>young</th>\n",
              "      <th>younger</th>\n",
              "      <th>youphone</th>\n",
              "      <th>youre</th>\n",
              "      <th>yourinclusive</th>\n",
              "      <th>yourjob</th>\n",
              "      <th>youuuuu</th>\n",
              "      <th>youwanna</th>\n",
              "      <th>yoville</th>\n",
              "      <th>yowifes</th>\n",
              "      <th>yoyyooo</th>\n",
              "      <th>yr</th>\n",
              "      <th>ystrday</th>\n",
              "      <th>yt</th>\n",
              "      <th>ything</th>\n",
              "      <th>yummmm</th>\n",
              "      <th>yummy</th>\n",
              "      <th>yun</th>\n",
              "      <th>yunny</th>\n",
              "      <th>yuo</th>\n",
              "      <th>yuou</th>\n",
              "      <th>yup</th>\n",
              "      <th>yupz</th>\n",
              "      <th>zac</th>\n",
              "      <th>zaher</th>\n",
              "      <th>zealand</th>\n",
              "      <th>zebra</th>\n",
              "      <th>zed</th>\n",
              "      <th>zero</th>\n",
              "      <th>zf</th>\n",
              "      <th>zhong</th>\n",
              "      <th>zindgi</th>\n",
              "      <th>zoe</th>\n",
              "      <th>zogtorius</th>\n",
              "      <th>zoom</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 5000 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    aa  aah  aathi  abi  ability  ...  zhong  zindgi  zoe  zogtorius  zoom\n",
              "0  0.0  0.0    0.0  0.0      0.0  ...    0.0     0.0  0.0        0.0   0.0\n",
              "1  0.0  0.0    0.0  0.0      0.0  ...    0.0     0.0  0.0        0.0   0.0\n",
              "2  0.0  0.0    0.0  0.0      0.0  ...    0.0     0.0  0.0        0.0   0.0\n",
              "3  0.0  0.0    0.0  0.0      0.0  ...    0.0     0.0  0.0        0.0   0.0\n",
              "4  0.0  0.0    0.0  0.0      0.0  ...    0.0     0.0  0.0        0.0   0.0\n",
              "\n",
              "[5 rows x 5000 columns]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "i3oXdX1JXGHb",
        "outputId": "bf28568d-ffcc-4a34-abef-8ee08c9ce62f"
      },
      "source": [
        "y.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ham</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   ham  spam\n",
              "0    1     0\n",
              "1    1     0\n",
              "2    0     1\n",
              "3    1     0\n",
              "4    1     0"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4thAxnvXB2J"
      },
      "source": [
        "y=y.iloc[:,1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcQ_GhFZXNmN",
        "outputId": "8b37f6bf-5db6-4721-9eee-a4c402332de4"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 0, 0, 0], dtype=uint8)"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxkhQeOdXPO8"
      },
      "source": [
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVzQ_qxmZwre"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmiAqybjaCar"
      },
      "source": [
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=.2,random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQMa0VQMbCV3",
        "outputId": "9c3b72fc-cddb-439d-ca0b-4a3aeb7969e1"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(4457, 5000)"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgUF8hTWbEfa"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wl_4kxWKbK0c"
      },
      "source": [
        "model=MultinomialNB()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pO7Xb8q5bPFN"
      },
      "source": [
        "model=model.fit(X_train,y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuo1ZjGbbSN9"
      },
      "source": [
        "y_pred=model.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUJmDZNXbV54"
      },
      "source": [
        "from sklearn.metrics import accuracy_score,confusion_matrix, f1_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95dhYT_PbfRF",
        "outputId": "b441fa1f-3d34-4a9e-d43f-ac319b3e0b01"
      },
      "source": [
        "confusion_matrix(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[965,   1],\n",
              "       [ 29, 120]])"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sOI3__h4bjKV",
        "outputId": "805a67a1-dd41-4e7a-83a6-930fbfe3639d"
      },
      "source": [
        "accuracy_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9730941704035875"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2gCoGYUbnA9",
        "outputId": "69ac184d-e9a9-409a-f635-0e65fe4af2c7"
      },
      "source": [
        "f1_score(y_test,y_pred)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8888888888888888"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IK-_E7pWeicP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0kEWascfZS9"
      },
      "source": [
        "import gensim"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drk7V5b1jwhN"
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NROkDSCWkH9U"
      },
      "source": [
        "para='''In machine learning and natural language processing, a topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body. Intuitively, given that a document is about a particular topic, one would expect particular words to appear in the document more or less frequently: \"dog\" and \"bone\" will appear more often in documents about dogs, \"cat\" and \"meow\" will appear in documents about cats, and \"the\" and \"is\" will appear approximately equally in both. A document typically concerns multiple topics in different proportions; thus, in a document that is 10% about cats and 90% about dogs, there would probably be about 9 times more dog words than cat words. The \"topics\" produced by topic modeling techniques are clusters of similar words. A topic model captures this intuition in a mathematical framework, which allows examining a set of documents and discovering, based on the statistics of the words in each, what the topics might be and what each document's balance of topics is.'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "V8eBPczqk3k0",
        "outputId": "372c4b54-fb99-4007-96b3-6b409bcdb3eb"
      },
      "source": [
        "para"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'In machine learning and natural language processing, a topic model is a type of statistical model for discovering the abstract \"topics\" that occur in a collection of documents. Topic modeling is a frequently used text-mining tool for discovery of hidden semantic structures in a text body. Intuitively, given that a document is about a particular topic, one would expect particular words to appear in the document more or less frequently: \"dog\" and \"bone\" will appear more often in documents about dogs, \"cat\" and \"meow\" will appear in documents about cats, and \"the\" and \"is\" will appear approximately equally in both. A document typically concerns multiple topics in different proportions; thus, in a document that is 10% about cats and 90% about dogs, there would probably be about 9 times more dog words than cat words. The \"topics\" produced by topic modeling techniques are clusters of similar words. A topic model captures this intuition in a mathematical framework, which allows examining a set of documents and discovering, based on the statistics of the words in each, what the topics might be and what each document\\'s balance of topics is.'"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piEki1hglM8o"
      },
      "source": [
        "\n",
        "text=re.sub('[^a-zA-Z]',' ',para)\n",
        "text=text.lower()\n",
        "\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZRdLQC-bl-WE",
        "outputId": "ba8a4fb1-094d-43c4-fbb1-756ddf5fb3cc"
      },
      "source": [
        "from nltk import sent_tokenize,word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "vWgbUMkJmlal",
        "outputId": "7934167f-0465-4bb7-ede3-06fdda52ad52"
      },
      "source": [
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'in machine learning and natural language processing  a topic model is a type of statistical model for discovering the abstract  topics  that occur in a collection of documents  topic modeling is a frequently used text mining tool for discovery of hidden semantic structures in a text body  intuitively  given that a document is about a particular topic  one would expect particular words to appear in the document more or less frequently   dog  and  bone  will appear more often in documents about dogs   cat  and  meow  will appear in documents about cats  and  the  and  is  will appear approximately equally in both  a document typically concerns multiple topics in different proportions  thus  in a document that is     about cats and     about dogs  there would probably be about   times more dog words than cat words  the  topics  produced by topic modeling techniques are clusters of similar words  a topic model captures this intuition in a mathematical framework  which allows examining a set of documents and discovering  based on the statistics of the words in each  what the topics might be and what each document s balance of topics is '"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wOco_Cgmsk2"
      },
      "source": [
        "sent=sent_tokenize(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XJQypVJjm-qY"
      },
      "source": [
        "sent=[word_tokenize(sen) for sen in sent]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHc7UgPsnB6-",
        "outputId": "0ff53894-92da-4bcc-be31-5b418d497de9"
      },
      "source": [
        "sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['in',\n",
              "  'machine',\n",
              "  'learning',\n",
              "  'and',\n",
              "  'natural',\n",
              "  'language',\n",
              "  'processing',\n",
              "  'a',\n",
              "  'topic',\n",
              "  'model',\n",
              "  'is',\n",
              "  'a',\n",
              "  'type',\n",
              "  'of',\n",
              "  'statistical',\n",
              "  'model',\n",
              "  'for',\n",
              "  'discovering',\n",
              "  'the',\n",
              "  'abstract',\n",
              "  'topics',\n",
              "  'that',\n",
              "  'occur',\n",
              "  'in',\n",
              "  'a',\n",
              "  'collection',\n",
              "  'of',\n",
              "  'documents',\n",
              "  'topic',\n",
              "  'modeling',\n",
              "  'is',\n",
              "  'a',\n",
              "  'frequently',\n",
              "  'used',\n",
              "  'text',\n",
              "  'mining',\n",
              "  'tool',\n",
              "  'for',\n",
              "  'discovery',\n",
              "  'of',\n",
              "  'hidden',\n",
              "  'semantic',\n",
              "  'structures',\n",
              "  'in',\n",
              "  'a',\n",
              "  'text',\n",
              "  'body',\n",
              "  'intuitively',\n",
              "  'given',\n",
              "  'that',\n",
              "  'a',\n",
              "  'document',\n",
              "  'is',\n",
              "  'about',\n",
              "  'a',\n",
              "  'particular',\n",
              "  'topic',\n",
              "  'one',\n",
              "  'would',\n",
              "  'expect',\n",
              "  'particular',\n",
              "  'words',\n",
              "  'to',\n",
              "  'appear',\n",
              "  'in',\n",
              "  'the',\n",
              "  'document',\n",
              "  'more',\n",
              "  'or',\n",
              "  'less',\n",
              "  'frequently',\n",
              "  'dog',\n",
              "  'and',\n",
              "  'bone',\n",
              "  'will',\n",
              "  'appear',\n",
              "  'more',\n",
              "  'often',\n",
              "  'in',\n",
              "  'documents',\n",
              "  'about',\n",
              "  'dogs',\n",
              "  'cat',\n",
              "  'and',\n",
              "  'meow',\n",
              "  'will',\n",
              "  'appear',\n",
              "  'in',\n",
              "  'documents',\n",
              "  'about',\n",
              "  'cats',\n",
              "  'and',\n",
              "  'the',\n",
              "  'and',\n",
              "  'is',\n",
              "  'will',\n",
              "  'appear',\n",
              "  'approximately',\n",
              "  'equally',\n",
              "  'in',\n",
              "  'both',\n",
              "  'a',\n",
              "  'document',\n",
              "  'typically',\n",
              "  'concerns',\n",
              "  'multiple',\n",
              "  'topics',\n",
              "  'in',\n",
              "  'different',\n",
              "  'proportions',\n",
              "  'thus',\n",
              "  'in',\n",
              "  'a',\n",
              "  'document',\n",
              "  'that',\n",
              "  'is',\n",
              "  'about',\n",
              "  'cats',\n",
              "  'and',\n",
              "  'about',\n",
              "  'dogs',\n",
              "  'there',\n",
              "  'would',\n",
              "  'probably',\n",
              "  'be',\n",
              "  'about',\n",
              "  'times',\n",
              "  'more',\n",
              "  'dog',\n",
              "  'words',\n",
              "  'than',\n",
              "  'cat',\n",
              "  'words',\n",
              "  'the',\n",
              "  'topics',\n",
              "  'produced',\n",
              "  'by',\n",
              "  'topic',\n",
              "  'modeling',\n",
              "  'techniques',\n",
              "  'are',\n",
              "  'clusters',\n",
              "  'of',\n",
              "  'similar',\n",
              "  'words',\n",
              "  'a',\n",
              "  'topic',\n",
              "  'model',\n",
              "  'captures',\n",
              "  'this',\n",
              "  'intuition',\n",
              "  'in',\n",
              "  'a',\n",
              "  'mathematical',\n",
              "  'framework',\n",
              "  'which',\n",
              "  'allows',\n",
              "  'examining',\n",
              "  'a',\n",
              "  'set',\n",
              "  'of',\n",
              "  'documents',\n",
              "  'and',\n",
              "  'discovering',\n",
              "  'based',\n",
              "  'on',\n",
              "  'the',\n",
              "  'statistics',\n",
              "  'of',\n",
              "  'the',\n",
              "  'words',\n",
              "  'in',\n",
              "  'each',\n",
              "  'what',\n",
              "  'the',\n",
              "  'topics',\n",
              "  'might',\n",
              "  'be',\n",
              "  'and',\n",
              "  'what',\n",
              "  'each',\n",
              "  'document',\n",
              "  's',\n",
              "  'balance',\n",
              "  'of',\n",
              "  'topics',\n",
              "  'is']]"
            ]
          },
          "execution_count": 78,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtsZSTmvne8f"
      },
      "source": [
        "for i in range(len(sent)):\n",
        "  sent[i]=[w for w in sent[i] if w not in stopwords.words('english')]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j8Kad988oDYu",
        "outputId": "63c74eb6-5a1d-4e23-a381-d84696274b3c"
      },
      "source": [
        "sent"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['machine',\n",
              "  'learning',\n",
              "  'natural',\n",
              "  'language',\n",
              "  'processing',\n",
              "  'topic',\n",
              "  'model',\n",
              "  'type',\n",
              "  'statistical',\n",
              "  'model',\n",
              "  'discovering',\n",
              "  'abstract',\n",
              "  'topics',\n",
              "  'occur',\n",
              "  'collection',\n",
              "  'documents',\n",
              "  'topic',\n",
              "  'modeling',\n",
              "  'frequently',\n",
              "  'used',\n",
              "  'text',\n",
              "  'mining',\n",
              "  'tool',\n",
              "  'discovery',\n",
              "  'hidden',\n",
              "  'semantic',\n",
              "  'structures',\n",
              "  'text',\n",
              "  'body',\n",
              "  'intuitively',\n",
              "  'given',\n",
              "  'document',\n",
              "  'particular',\n",
              "  'topic',\n",
              "  'one',\n",
              "  'would',\n",
              "  'expect',\n",
              "  'particular',\n",
              "  'words',\n",
              "  'appear',\n",
              "  'document',\n",
              "  'less',\n",
              "  'frequently',\n",
              "  'dog',\n",
              "  'bone',\n",
              "  'appear',\n",
              "  'often',\n",
              "  'documents',\n",
              "  'dogs',\n",
              "  'cat',\n",
              "  'meow',\n",
              "  'appear',\n",
              "  'documents',\n",
              "  'cats',\n",
              "  'appear',\n",
              "  'approximately',\n",
              "  'equally',\n",
              "  'document',\n",
              "  'typically',\n",
              "  'concerns',\n",
              "  'multiple',\n",
              "  'topics',\n",
              "  'different',\n",
              "  'proportions',\n",
              "  'thus',\n",
              "  'document',\n",
              "  'cats',\n",
              "  'dogs',\n",
              "  'would',\n",
              "  'probably',\n",
              "  'times',\n",
              "  'dog',\n",
              "  'words',\n",
              "  'cat',\n",
              "  'words',\n",
              "  'topics',\n",
              "  'produced',\n",
              "  'topic',\n",
              "  'modeling',\n",
              "  'techniques',\n",
              "  'clusters',\n",
              "  'similar',\n",
              "  'words',\n",
              "  'topic',\n",
              "  'model',\n",
              "  'captures',\n",
              "  'intuition',\n",
              "  'mathematical',\n",
              "  'framework',\n",
              "  'allows',\n",
              "  'examining',\n",
              "  'set',\n",
              "  'documents',\n",
              "  'discovering',\n",
              "  'based',\n",
              "  'statistics',\n",
              "  'words',\n",
              "  'topics',\n",
              "  'might',\n",
              "  'document',\n",
              "  'balance',\n",
              "  'topics']]"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPtfjWqAn3U9"
      },
      "source": [
        "model=Word2Vec(sent,min_count=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0d-mz_1n9RW"
      },
      "source": [
        "words=model.wv.vocab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seq5eTPQpkM9",
        "outputId": "9ec24a34-4de9-48de-f1ae-b21babb5903a"
      },
      "source": [
        "words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'abstract': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaab50>,\n",
              " 'allows': <gensim.models.keyedvectors.Vocab at 0x7f25cbd4f090>,\n",
              " 'appear': <gensim.models.keyedvectors.Vocab at 0x7f25cc088650>,\n",
              " 'approximately': <gensim.models.keyedvectors.Vocab at 0x7f25cbddfa10>,\n",
              " 'balance': <gensim.models.keyedvectors.Vocab at 0x7f25cbd4fe50>,\n",
              " 'based': <gensim.models.keyedvectors.Vocab at 0x7f25cbd4f3d0>,\n",
              " 'body': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa890>,\n",
              " 'bone': <gensim.models.keyedvectors.Vocab at 0x7f25cc72c910>,\n",
              " 'captures': <gensim.models.keyedvectors.Vocab at 0x7f25cbd4fa50>,\n",
              " 'cat': <gensim.models.keyedvectors.Vocab at 0x7f25cc5f2790>,\n",
              " 'cats': <gensim.models.keyedvectors.Vocab at 0x7f25cbddf150>,\n",
              " 'clusters': <gensim.models.keyedvectors.Vocab at 0x7f25cc0cc650>,\n",
              " 'collection': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa810>,\n",
              " 'concerns': <gensim.models.keyedvectors.Vocab at 0x7f25cbddf450>,\n",
              " 'different': <gensim.models.keyedvectors.Vocab at 0x7f25cbddf390>,\n",
              " 'discovering': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa850>,\n",
              " 'discovery': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa190>,\n",
              " 'document': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaad50>,\n",
              " 'documents': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa790>,\n",
              " 'dog': <gensim.models.keyedvectors.Vocab at 0x7f25cc088d90>,\n",
              " 'dogs': <gensim.models.keyedvectors.Vocab at 0x7f25cbfe7e50>,\n",
              " 'equally': <gensim.models.keyedvectors.Vocab at 0x7f25cbddff50>,\n",
              " 'examining': <gensim.models.keyedvectors.Vocab at 0x7f25cbd4f690>,\n",
              " 'expect': <gensim.models.keyedvectors.Vocab at 0x7f25cc0885d0>,\n",
              " 'framework': <gensim.models.keyedvectors.Vocab at 0x7f25cbd4f650>,\n",
              " 'frequently': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaaa50>,\n",
              " 'given': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaad90>,\n",
              " 'hidden': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa4d0>,\n",
              " 'intuition': <gensim.models.keyedvectors.Vocab at 0x7f25cbd4f110>,\n",
              " 'intuitively': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa550>,\n",
              " 'language': <gensim.models.keyedvectors.Vocab at 0x7f25cc5fa250>,\n",
              " 'learning': <gensim.models.keyedvectors.Vocab at 0x7f25cbdef8d0>,\n",
              " 'less': <gensim.models.keyedvectors.Vocab at 0x7f25cc088890>,\n",
              " 'machine': <gensim.models.keyedvectors.Vocab at 0x7f25cbdef510>,\n",
              " 'mathematical': <gensim.models.keyedvectors.Vocab at 0x7f25cbd4f390>,\n",
              " 'meow': <gensim.models.keyedvectors.Vocab at 0x7f25cc5f2850>,\n",
              " 'might': <gensim.models.keyedvectors.Vocab at 0x7f25cbd4fc90>,\n",
              " 'mining': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa690>,\n",
              " 'model': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaac10>,\n",
              " 'modeling': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaaf10>,\n",
              " 'multiple': <gensim.models.keyedvectors.Vocab at 0x7f25cbddf310>,\n",
              " 'natural': <gensim.models.keyedvectors.Vocab at 0x7f25cbdef450>,\n",
              " 'occur': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa150>,\n",
              " 'often': <gensim.models.keyedvectors.Vocab at 0x7f25cbfe7490>,\n",
              " 'one': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa910>,\n",
              " 'particular': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa450>,\n",
              " 'probably': <gensim.models.keyedvectors.Vocab at 0x7f25cbddf5d0>,\n",
              " 'processing': <gensim.models.keyedvectors.Vocab at 0x7f25cc396b90>,\n",
              " 'produced': <gensim.models.keyedvectors.Vocab at 0x7f25cbfa5590>,\n",
              " 'proportions': <gensim.models.keyedvectors.Vocab at 0x7f25cbddfe50>,\n",
              " 'semantic': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaaa10>,\n",
              " 'set': <gensim.models.keyedvectors.Vocab at 0x7f25cbd4f210>,\n",
              " 'similar': <gensim.models.keyedvectors.Vocab at 0x7f25cbd4fbd0>,\n",
              " 'statistical': <gensim.models.keyedvectors.Vocab at 0x7f25cc5fac50>,\n",
              " 'statistics': <gensim.models.keyedvectors.Vocab at 0x7f25cbd4f9d0>,\n",
              " 'structures': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa8d0>,\n",
              " 'techniques': <gensim.models.keyedvectors.Vocab at 0x7f25cbfa5b50>,\n",
              " 'text': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa9d0>,\n",
              " 'thus': <gensim.models.keyedvectors.Vocab at 0x7f25cbddf090>,\n",
              " 'times': <gensim.models.keyedvectors.Vocab at 0x7f25cbddf0d0>,\n",
              " 'tool': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa6d0>,\n",
              " 'topic': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaad10>,\n",
              " 'topics': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa410>,\n",
              " 'type': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaaa90>,\n",
              " 'typically': <gensim.models.keyedvectors.Vocab at 0x7f25cbddf210>,\n",
              " 'used': <gensim.models.keyedvectors.Vocab at 0x7f25cbdaa310>,\n",
              " 'words': <gensim.models.keyedvectors.Vocab at 0x7f25cc088fd0>,\n",
              " 'would': <gensim.models.keyedvectors.Vocab at 0x7f25cc088c90>}"
            ]
          },
          "execution_count": 89,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unkBF_gbpk2n"
      },
      "source": [
        "vec=model.wv['words']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI8NfSECps5J",
        "outputId": "a5ba5a59-1605-4eaa-cd5b-8db884bb3f4c"
      },
      "source": [
        "vec.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W18N_LB_pyBD"
      },
      "source": [
        "similar=model.wv.most_similar('words')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9zWbNFLrrLe9",
        "outputId": "674630cd-9451-4e6b-e7f8-ec49a9789e38"
      },
      "source": [
        "similar"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('would', 0.22369980812072754),\n",
              " ('modeling', 0.21206238865852356),\n",
              " ('document', 0.18851882219314575),\n",
              " ('body', 0.182593435049057),\n",
              " ('concerns', 0.18165156245231628),\n",
              " ('structures', 0.1630992889404297),\n",
              " ('appear', 0.15120160579681396),\n",
              " ('natural', 0.14578168094158173),\n",
              " ('similar', 0.13451234996318817),\n",
              " ('cats', 0.1316005438566208)]"
            ]
          },
          "execution_count": 95,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5DMBQL1rMpR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}